{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "import folium\n",
    "from folium.plugins import HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Enes\\anaconda3\\envs\\gputorch\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"token-classification\", model=\"akdeniz27/bert-base-turkish-cased-ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ve Etiketler:\n",
      "Token: kahraman, Etiket: B-LOC\n",
      "Token: ##maraş, Etiket: B-LOC\n",
      "Token: elbis, Etiket: B-LOC\n",
      "Token: ##tan, Etiket: B-LOC\n",
      "Token: p, Etiket: B-LOC\n",
      "Token: ##ınar, Etiket: B-LOC\n",
      "Token: ##başı, Etiket: B-LOC\n",
      "Token: p, Etiket: B-LOC\n",
      "Token: ##ınar, Etiket: B-LOC\n",
      "Token: ##başı, Etiket: B-LOC\n",
      "Token: cem, Etiket: B-PER\n",
      "Token: ##re, Etiket: B-PER\n",
      "Token: kahraman, Etiket: B-LOC\n",
      "Token: ##maraş, Etiket: B-LOC\n",
      "\n",
      "Location:\n",
      "kahramanmaraş elbistan pınarbaşı mahallesi pınarbaşı caddesi kahramanmaraş\n"
     ]
    }
   ],
   "source": [
    "text = \"arkadaşımıza ulaşamıyoruz kahramanmaraş elbistan pınarbaşı mahallesi pınarbaşı caddesi cemre yapıcı kahramanmaraş deprem\"\n",
    "\n",
    "result = pipe(text)\n",
    "\n",
    "print(\"Token ve Etiketler:\")\n",
    "\n",
    "location = \"\"\n",
    "address_keywords = [\"mahallesi\", \"caddesi\", \"sokak\", \"bulvarı\", \"köyü\", \"yolu\", \"mevkii\", \"mah.\", \"cad.\", \"sok.\", \"bul.\", \"köy.\", \"yol.\", \"mek.\",\"apartman\",\"apt\"]\n",
    "\n",
    "loc_tokens = []\n",
    "for entity in result:\n",
    "    token = entity['word']\n",
    "    label = entity['entity']\n",
    "    print(f\"Token: {token}, Etiket: {label}\")\n",
    "\n",
    "    if \"LOC\" in label:  \n",
    "        if token.startswith(\"##\"):\n",
    "            loc_tokens[-1] += token.lstrip(\"##\")  \n",
    "        else:\n",
    "            loc_tokens.append(token)\n",
    "\n",
    "words = text.split()  \n",
    "for i, word in enumerate(words):\n",
    "    if any(loc in word for loc in loc_tokens):\n",
    "        location += word + \" \" \n",
    "    if any(keyword in word.lower() for keyword in address_keywords):\n",
    "            location += word + \" \" \n",
    "loc_tokens\n",
    "print(\"\\nLocation:\")\n",
    "print(location.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ve Etiketler:\n",
      "Token: ak, Etiket: B-LOC\n",
      "Token: ##asy, Etiket: B-LOC\n",
      "Token: ##a, Etiket: B-LOC\n",
      "Token: bal, Etiket: I-PER\n",
      "Token: ##cı, Etiket: I-PER\n",
      "Token: sar, Etiket: B-LOC\n",
      "Token: ##a, Etiket: B-LOC\n",
      "Token: hata, Etiket: B-LOC\n",
      "Token: ##y, Etiket: B-LOC\n",
      "Token: ant, Etiket: B-LOC\n",
      "Token: ##ak, Etiket: B-LOC\n",
      "Token: ##ya, Etiket: B-LOC\n",
      "\n",
      "Location:\n",
      "akasya sara hatay antakya\n"
     ]
    }
   ],
   "source": [
    "text = \"çocuk enkazın altında ai̇leşi̇ i̇ki̇ gündür acil müdahale edi̇lmesi̇ni̇ bekliyor adres akasya mahallesi şükrü balcı caddesi sara apartmanı hatay antakya iletişim deprem sondakikadeprem acil acildeprem\"\n",
    "\n",
    "result = pipe(text)\n",
    "\n",
    "print(\"Token ve Etiketler:\")\n",
    "\n",
    "location = \"\"\n",
    "\n",
    "loc_tokens = []\n",
    "for entity in result:\n",
    "    token = entity['word']\n",
    "    label = entity['entity']\n",
    "    print(f\"Token: {token}, Etiket: {label}\")\n",
    "\n",
    "    # LOC etiketli tokenları topla\n",
    "    if 'LOC' in label:  \n",
    "            if not token.startswith('##'):  \n",
    "                if location:  \n",
    "                    location += \" \" \n",
    "                location += token\n",
    "            else:\n",
    "                location += token.lstrip('##')  \n",
    "\n",
    "\n",
    "print(\"\\nLocation:\")\n",
    "print(location.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adres: hatay esenlik mahallesi\n",
      "Enlem: 36.2059571, Boylam: 36.1478466\n"
     ]
    }
   ],
   "source": [
    "geolocator = Nominatim(user_agent=\"geoapi\")\n",
    "\n",
    "# Adres olarak tam metni belirtiyoruz\n",
    "address = \"hatay esenlik mahallesi\"\n",
    "\n",
    "# Adresi enlem ve boylama çevir\n",
    "location = geolocator.geocode(address)\n",
    "\n",
    "if location:\n",
    "    print(f\"Adres: {address}\")\n",
    "    print(f\"Enlem: {location.latitude}, Boylam: {location.longitude}\")\n",
    "else:\n",
    "    print(f\"Adres bulunamadı: {address}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tweets_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalize(text):\n",
    "    words = text.split()\n",
    "    capitalized_words = [word.capitalize() for word in words]\n",
    "    capitalized_text = ' '.join(capitalized_words)\n",
    "    return capitalized_text\n",
    "\n",
    "df['content_wo_tokenize_capitalize'] = df['content_wo_normalize'].apply(capitalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_from_text(text):\n",
    "    if not text.strip():\n",
    "        return None \n",
    "    result = pipe(text) \n",
    "    location = \"\" \n",
    "    \n",
    "    for entity in result:\n",
    "        token = entity['word']\n",
    "        label = entity['entity']\n",
    "\n",
    "        if 'LOC' in label:  \n",
    "            if not token.startswith('##'):  \n",
    "                if location:  \n",
    "                    location += \" \" \n",
    "                location += token\n",
    "            else:\n",
    "                location += token.lstrip('##')  \n",
    "   \n",
    "\n",
    "    return location.strip() if location else None\n",
    "\n",
    "df['location'] = df['content_wo_tokenize_capitalize'].apply(get_location_from_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(text):\n",
    "    if not text:\n",
    "        return text\n",
    "    words = text.split()\n",
    "    unique_words = list(set(words))\n",
    "    unique_words.sort(key=lambda x: words.index(x))  \n",
    "    return ' '.join(unique_words)\n",
    "\n",
    "df['location_unique'] = df['location'].apply(remove_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Türkiye Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sehirler = [\n",
    "    \"Adana\", \"Adıyaman\", \"Afyon\", \"Ağrı\", \"Amasya\", \"Ankara\", \"Antalya\", \"Artvin\",\n",
    "    \"Aydın\", \"Balıkesir\", \"Bilecik\", \"Bingöl\", \"Bitlis\", \"Bolu\", \"Burdur\", \"Bursa\", \"Çanakkale\",\n",
    "    \"Çankırı\", \"Çorum\", \"Denizli\", \"Diyarbakır\", \"Edirne\", \"Elazığ\", \"Erzincan\", \"Erzurum\", \n",
    "    \"Eskişehir\", \"Gaziantep\", \"Giresun\", \"Gümüşhane\", \"Hakkari\", \"Hatay\", \"Isparta\", \"Mersin\",\n",
    "    \"İstanbul\", \"İzmir\", \"Kars\", \"Kastamonu\", \"Kayseri\", \"Kırklareli\", \"Kırşehir\", \"Kocaeli\",\n",
    "    \"Konya\", \"Kütahya\", \"Malatya\", \"Manisa\", \"Kahramanmaraş\", \"Mardin\", \"Muğla\", \"Muş\", \n",
    "    \"Nevşehir\", \"Niğde\", \"Ordu\", \"Rize\", \"Sakarya\", \"Samsun\", \"Siirt\", \"Sinop\", \"Sivas\", \n",
    "    \"Tekirdağ\", \"Tokat\", \"Trabzon\", \"Tunceli\", \"Şanlıurfa\", \"Uşak\", \"Van\", \"Yozgat\", \n",
    "    \"Zonguldak\", \"Aksaray\", \"Bayburt\", \"Karaman\", \"Kırıkkale\", \"Batman\", \"Şırnak\", \n",
    "    \"Bartın\", \"Ardahan\", \"Iğdır\", \"Yalova\", \"Karabük\", \"Kilis\", \"Osmaniye\", \"Düzce\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_location'] = df['location_unique'].apply(lambda x: x.split() if pd.notnull(x) else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cities(tokens, city_list):\n",
    "    if not tokens:  \n",
    "        return []\n",
    "    matches = []\n",
    "    for city in city_list:\n",
    "        for token in tokens:\n",
    "            if re.search(r'\\b' + re.escape(city) + r'\\b', token, re.IGNORECASE): \n",
    "                matches.append(city)\n",
    "    return list(set(matches))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['city'] = df['tokenized_location'].apply(lambda x: extract_cities(x, sehirler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_exploded = df['city'].explode()\n",
    "city_count = city_exploded.value_counts()\n",
    "city_count_df = city_count.reset_index()\n",
    "city_count_df.columns = ['City', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hatay</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kahramanmaraş</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adıyaman</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gaziantep</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malatya</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City  Count\n",
       "0          Hatay    423\n",
       "1  Kahramanmaraş    208\n",
       "2       Adıyaman    166\n",
       "3      Gaziantep     87\n",
       "4        Malatya     64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get latitude & longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"geoapi\")\n",
    "\n",
    "def get_coordinates(address):\n",
    "    if not address or pd.isna(address):\n",
    "        return None, None\n",
    "    try:\n",
    "        location = geolocator.geocode(address, timeout=10)\n",
    "        if location:\n",
    "            return location.latitude, location.longitude\n",
    "        else:\n",
    "            return None, None\n",
    "    except GeocoderTimedOut:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_count_df[['Latitude', 'Longitude']] = city_count_df['City'].apply(\n",
    "    lambda city: pd.Series(get_coordinates(city))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[41.008238, 28.978359], zoom_start=6)\n",
    "heat_data = [[row['Latitude'], row['Longitude'], row['Count']] for index, row in city_count_df.iterrows()]\n",
    "HeatMap(heat_data, \n",
    "        min_opacity=0.4,  \n",
    "        max_opacity=0.9, \n",
    "        radius=50,  \n",
    "        blur=30,  \n",
    "        gradient={  \n",
    "            0.1: 'blue',   \n",
    "            0.3: 'lime',   \n",
    "            0.5: 'yellow',  \n",
    "            0.7: 'orange',\n",
    "            1.0: 'red'      \n",
    "        }).add_to(m)\n",
    "\n",
    "for index, row in city_count_df.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['Latitude'], row['Longitude']],\n",
    "        radius=20,  # Marker boyutu\n",
    "        color='black',\n",
    "        fill=True,\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"{row['City']}: {row['Count']}\",\n",
    "        tooltip=f\"{row['City']} - {row['Count']} people\"\n",
    "    ).add_to(m)\n",
    "\n",
    "m.save('heatmap_with_numbers.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Count</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hatay</td>\n",
       "      <td>423</td>\n",
       "      <td>36.202547</td>\n",
       "      <td>36.160291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kahramanmaraş</td>\n",
       "      <td>208</td>\n",
       "      <td>37.783034</td>\n",
       "      <td>36.830655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adıyaman</td>\n",
       "      <td>166</td>\n",
       "      <td>37.789360</td>\n",
       "      <td>38.314110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gaziantep</td>\n",
       "      <td>87</td>\n",
       "      <td>37.062832</td>\n",
       "      <td>37.379262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malatya</td>\n",
       "      <td>64</td>\n",
       "      <td>38.348715</td>\n",
       "      <td>38.319067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City  Count   Latitude  Longitude\n",
       "0          Hatay    423  36.202547  36.160291\n",
       "1  Kahramanmaraş    208  37.783034  36.830655\n",
       "2       Adıyaman    166  37.789360  38.314110\n",
       "3      Gaziantep     87  37.062832  37.379262\n",
       "4        Malatya     64  38.348715  38.319067"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datawith_city.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adres: Kahramanmaraş Elbistan Pınarbaşı\n",
      "Enlem: 38.1914464, Boylam: 37.2055864\n"
     ]
    }
   ],
   "source": [
    "geolocator = Nominatim(user_agent=\"geoapi\")\n",
    "\n",
    "address = \"Kahramanmaraş Elbistan Pınarbaşı Mahallesi Caddesi\"\n",
    "location = geolocator.geocode(address)\n",
    "\n",
    "if location:\n",
    "    print(f\"Adres: {address}\")\n",
    "    print(f\"Enlem: {location.latitude}, Boylam: {location.longitude}\")\n",
    "else:\n",
    "    print(f\"Adres bulunamadı: {address}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
