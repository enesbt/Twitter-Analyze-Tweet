{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Enes\\anaconda3\\envs\\gputorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Enes\\anaconda3\\envs\\gputorch\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Enes\\anaconda3\\envs\\gputorch\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"token-classification\", model=\"akdeniz27/bert-base-turkish-cased-ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ve Etiketler:\n",
      "Token: AM, Etiket: B-ORG\n",
      "Token: ##B, Etiket: B-ORG\n",
      "Token: ##UL, Etiket: B-ORG\n",
      "Token: ##ANS, Etiket: B-ORG\n",
      "Token: Cumhuriyet, Etiket: B-LOC\n",
      "Token: Mahallesi, Etiket: I-LOC\n",
      "Token: 30, Etiket: I-LOC\n",
      "Token: ##2, Etiket: I-LOC\n",
      "Token: Sokak, Etiket: I-LOC\n",
      "Token: Gök, Etiket: I-LOC\n",
      "Token: ##kuş, Etiket: I-LOC\n",
      "Token: ##ağı, Etiket: I-LOC\n",
      "Token: Sitesi, Etiket: I-LOC\n",
      "Token: B, Etiket: I-LOC\n",
      "Token: Hatay, Etiket: B-LOC\n",
      "Token: Kırık, Etiket: B-LOC\n",
      "Token: ##han, Etiket: B-LOC\n",
      "\n",
      "Location:\n",
      "Cumhuriyet Mahallesi 302 Sokak Gökkuşağı Sitesi B Hatay Kırık ##han\n"
     ]
    }
   ],
   "source": [
    "text = \"AMBULANS Cumhuriyet Mahallesi 302 Sokak Gökkuşağı Sitesi B Blok Hatay/Kırıkhan. \"\n",
    "\n",
    "result = pipe(text)\n",
    "\n",
    "print(\"Token ve Etiketler:\")\n",
    "location = \"\"  \n",
    "for entity in result:\n",
    "    token = entity['word']\n",
    "    label = entity['entity']\n",
    "    \n",
    "    print(f\"Token: {token}, Etiket: {label}\")\n",
    "    \n",
    "    if label == 'B-LOC':\n",
    "        if location:  \n",
    "            location += \" \"\n",
    "        location += token\n",
    "    elif label == 'I-LOC':  \n",
    "        if token.startswith('##'): \n",
    "            location += token.lstrip('##') \n",
    "        else:\n",
    "            location += \" \" + token  \n",
    "\n",
    "print(\"\\nLocation:\")\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
